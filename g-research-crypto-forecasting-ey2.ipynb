{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e29b5b",
   "metadata": {
    "papermill": {
     "duration": 0.019481,
     "end_time": "2022-02-15T17:45:00.441499",
     "exception": false,
     "start_time": "2022-02-15T17:45:00.422018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reference:\n",
    "\n",
    "Kaggle \\\n",
    "[G-Research Crypto Forecasting - baseline & FE](https://www.kaggle.com/vbmokin/g-research-crypto-forecasting-baseline-fe)\\\n",
    "[G-Research- Starter LGBM Pipeline(copied)](https://www.kaggle.com/yliu27/g-research-starter-lgbm-pipeline-copied)\\\n",
    "[[GResearch] Simple LGB Starter](https://www.kaggle.com/code1110/gresearch-simple-lgb-starter)\\\n",
    "[LightGBM with Sklearn pipelines](https://www.kaggle.com/paweljankiewicz/lightgbm-with-sklearn-pipelines)\\\n",
    "[Parameter grid search LGBM with scikit-learn](https://www.kaggle.com/bitit1994/parameter-grid-search-lgbm-with-scikit-learn)\n",
    "\n",
    "External \\\n",
    "[You Are Missing Out on LightGBM. It Crushes XGBoost in Every Aspect](https://towardsdatascience.com/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a8024",
   "metadata": {
    "papermill": {
     "duration": 0.018013,
     "end_time": "2022-02-15T17:45:00.478541",
     "exception": false,
     "start_time": "2022-02-15T17:45:00.460528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7fa96a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-15T17:45:00.523580Z",
     "iopub.status.busy": "2022-02-15T17:45:00.522934Z",
     "iopub.status.idle": "2022-02-15T17:45:00.537723Z",
     "shell.execute_reply": "2022-02-15T17:45:00.538241Z",
     "shell.execute_reply.started": "2022-02-15T07:30:42.370264Z"
    },
    "papermill": {
     "duration": 0.041986,
     "end_time": "2022-02-15T17:45:00.538538",
     "exception": false,
     "start_time": "2022-02-15T17:45:00.496552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/g-research-crypto-forecasting/example_sample_submission.csv\n",
      "/kaggle/input/g-research-crypto-forecasting/asset_details.csv\n",
      "/kaggle/input/g-research-crypto-forecasting/example_test.csv\n",
      "/kaggle/input/g-research-crypto-forecasting/train.csv\n",
      "/kaggle/input/g-research-crypto-forecasting/supplemental_train.csv\n",
      "/kaggle/input/g-research-crypto-forecasting/gresearch_crypto/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/g-research-crypto-forecasting/gresearch_crypto/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb86284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:45:00.580441Z",
     "iopub.status.busy": "2022-02-15T17:45:00.579463Z",
     "iopub.status.idle": "2022-02-15T17:46:09.015237Z",
     "shell.execute_reply": "2022-02-15T17:46:09.013997Z",
     "shell.execute_reply.started": "2022-02-15T07:30:42.395191Z"
    },
    "papermill": {
     "duration": 68.457425,
     "end_time": "2022-02-15T17:46:09.015414",
     "exception": false,
     "start_time": "2022-02-15T17:45:00.557989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/kaggle/input/g-research-crypto-forecasting')\n",
    "# somehow need to run this before importing competition API\n",
    "\n",
    "import gresearch_crypto\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "dir_in = '/kaggle/input/g-research-crypto-forecasting/'\n",
    "file_train = 'train.csv'\n",
    "file_asset_details = 'asset_details.csv'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(dir_in, file_train))\n",
    "df_asset_details = pd.read_csv(os.path.join(dir_in, file_asset_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f079bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:09.060351Z",
     "iopub.status.busy": "2022-02-15T17:46:09.059287Z",
     "iopub.status.idle": "2022-02-15T17:46:09.063998Z",
     "shell.execute_reply": "2022-02-15T17:46:09.064529Z",
     "shell.execute_reply.started": "2022-02-15T07:31:49.600047Z"
    },
    "papermill": {
     "duration": 0.028834,
     "end_time": "2022-02-15T17:46:09.064712",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.035878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "fix_all_seeds(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b870e34b",
   "metadata": {
    "papermill": {
     "duration": 0.019572,
     "end_time": "2022-02-15T17:46:09.104808",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.085236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c610e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:09.146396Z",
     "iopub.status.busy": "2022-02-15T17:46:09.145747Z",
     "iopub.status.idle": "2022-02-15T17:46:09.153910Z",
     "shell.execute_reply": "2022-02-15T17:46:09.154455Z",
     "shell.execute_reply.started": "2022-02-15T07:31:49.606423Z"
    },
    "papermill": {
     "duration": 0.030742,
     "end_time": "2022-02-15T17:46:09.154619",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.123877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    \n",
    "    df = df.set_index('timestamp')\n",
    "    \n",
    "    df['upper_shadow'] = df['High'] / df[['Close', 'Open']].max(axis=1)\n",
    "    df['lower_shadow'] = df[['Close', 'Open']].min(axis=1) / df['Low']\n",
    "    df['open2close'] = df['Close'] / df['Open']\n",
    "    df['high2low'] = df['High'] / df['Low']\n",
    "    \n",
    "    mean_price = df[['Open', 'High', 'Low', 'Close']].mean(axis=1)\n",
    "    median_price = df[['Open', 'High', 'Low', 'Close']].median(axis=1)\n",
    "    \n",
    "    df['high2mean'] = df['High'] / mean_price\n",
    "    df['low2mean'] = df['Low'] / mean_price\n",
    "    df['high2median'] = df['High'] / median_price\n",
    "    df['low2median'] = df['Low'] / median_price\n",
    "    df['volume2count'] = df['Volume'] / (df['Count'] + 1)\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1434550c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:09.194774Z",
     "iopub.status.busy": "2022-02-15T17:46:09.194101Z",
     "iopub.status.idle": "2022-02-15T17:46:09.199221Z",
     "shell.execute_reply": "2022-02-15T17:46:09.199703Z",
     "shell.execute_reply.started": "2022-02-15T07:31:49.620976Z"
    },
    "papermill": {
     "duration": 0.026552,
     "end_time": "2022-02-15T17:46:09.199865",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.173313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_asset_data(df_train, asset_id):\n",
    "    \n",
    "    df = df_train[df_train[\"Asset_ID\"] == asset_id].copy()\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    y = df['Target'].copy()\n",
    "    y = y.fillna(0)\n",
    "    X = df.drop('Target', axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f214a04d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:09.243249Z",
     "iopub.status.busy": "2022-02-15T17:46:09.242569Z",
     "iopub.status.idle": "2022-02-15T17:46:09.245571Z",
     "shell.execute_reply": "2022-02-15T17:46:09.245044Z",
     "shell.execute_reply.started": "2022-02-15T07:31:49.632404Z"
    },
    "papermill": {
     "duration": 0.02722,
     "end_time": "2022-02-15T17:46:09.245721",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.218501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr(y_pred, y):\n",
    "    corr = np.corrcoef(y_pred, y)[0,1]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dfd62b",
   "metadata": {
    "papermill": {
     "duration": 0.018264,
     "end_time": "2022-02-15T17:46:09.282651",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.264387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f1ee33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:09.326824Z",
     "iopub.status.busy": "2022-02-15T17:46:09.326159Z",
     "iopub.status.idle": "2022-02-15T17:46:11.498097Z",
     "shell.execute_reply": "2022-02-15T17:46:11.497458Z",
     "shell.execute_reply.started": "2022-02-15T07:31:49.648505Z"
    },
    "papermill": {
     "duration": 2.197026,
     "end_time": "2022-02-15T17:46:11.498267",
     "exception": false,
     "start_time": "2022-02-15T17:46:09.301241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "# customize class for feature transformation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class GetFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = get_features(X)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0bdf36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:11.540519Z",
     "iopub.status.busy": "2022-02-15T17:46:11.539843Z",
     "iopub.status.idle": "2022-02-15T17:46:11.544958Z",
     "shell.execute_reply": "2022-02-15T17:46:11.544351Z",
     "shell.execute_reply.started": "2022-02-15T07:31:51.775698Z"
    },
    "papermill": {
     "duration": 0.027428,
     "end_time": "2022-02-15T17:46:11.545087",
     "exception": false,
     "start_time": "2022-02-15T17:46:11.517659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = ['Asset_ID']\n",
    "num_cols = ['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP',\n",
    "            'upper_shadow', 'lower_shadow', 'open2close', 'high2low', 'high2mean', 'low2mean', 'high2median', 'low2median', 'volume2count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e685eb",
   "metadata": {
    "papermill": {
     "duration": 0.019029,
     "end_time": "2022-02-15T17:46:11.583442",
     "exception": false,
     "start_time": "2022-02-15T17:46:11.564413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[hyper parameter optimization - suggested parameter grid](https://github.com/Microsoft/LightGBM/issues/695)\n",
    "\n",
    ">For heavily unbalanced datasets such as 1:10000:\n",
    ">\n",
    ">max_bin: keep it only for memory pressure, not to tune (otherwise overfitting)\\\n",
    ">learning rate: keep it only for training speed, not to tune (otherwise overfitting)\\\n",
    ">n_estimators: must be infinite (like 9999999) and use early stopping to auto-tune (otherwise overfitting)\\\n",
    ">num_leaves: [7, 4095]\\\n",
    ">max_depth: [2, 63] and infinite (I personally saw metric performance increases with such 63 depth with small number of leaves on sparse unbalanced datasets)\\\n",
    ">scale_pos_weight: [1, 10000] (if over 10000, something might be wrong because I never saw it that good after 5000)\\\n",
    ">min_child_weight: [0.01, (sample size / 1000)] if you are using logloss (think about the hessian possible value range before putting \"sample size / 1000\", it is dataset-dependent and loss-dependent)\\\n",
    ">subsample: [0.4, 1]\\\n",
    ">bagging_freq: only 1, keep as is (otherwise overfitting)\\\n",
    ">colsample_bytree: [0.4, 1]\\\n",
    ">is_unbalance: false (make your own weighting with scale_pos_weight)\\\n",
    ">USE A CUSTOM METRIC (to reflect reality without weighting, otherwise you have weights inside your metric with premade metrics like xgboost)\\\n",
    ">Never tune these parameters unless you have an explicit requirement to tune them:\n",
    ">\n",
    ">Learning rate (lower means longer to train but more accurate, higher means smaller to train but less accurate)\\\n",
    ">Number of boosting iterations (automatically tuned with early stopping and learning rate)\\\n",
    ">Maximum number of bins (RAM dependent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf68af0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:11.629722Z",
     "iopub.status.busy": "2022-02-15T17:46:11.629053Z",
     "iopub.status.idle": "2022-02-15T17:46:11.630664Z",
     "shell.execute_reply": "2022-02-15T17:46:11.631157Z",
     "shell.execute_reply.started": "2022-02-15T07:31:51.782008Z"
    },
    "papermill": {
     "duration": 0.026683,
     "end_time": "2022-02-15T17:46:11.631352",
     "exception": false,
     "start_time": "2022-02-15T17:46:11.604669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 10000,\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.4,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1,\n",
    "    'seed': 46,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb6c4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:11.673581Z",
     "iopub.status.busy": "2022-02-15T17:46:11.672939Z",
     "iopub.status.idle": "2022-02-15T17:46:11.677121Z",
     "shell.execute_reply": "2022-02-15T17:46:11.677740Z",
     "shell.execute_reply.started": "2022-02-15T07:31:51.793479Z"
    },
    "papermill": {
     "duration": 0.027382,
     "end_time": "2022-02-15T17:46:11.677912",
     "exception": false,
     "start_time": "2022-02-15T17:46:11.650530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_lgbm = Pipeline(steps=[\n",
    "    ('get_feature', GetFeatureTransformer()),\n",
    "    ('transform_columns', ColumnTransformer([\n",
    "        ('tf_num', StandardScaler(), num_cols),\n",
    "        ('tf_cat', OneHotEncoder(), cat_cols)\n",
    "    ])),\n",
    "    ('model', LGBMRegressor(**params))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0799166",
   "metadata": {
    "papermill": {
     "duration": 0.018844,
     "end_time": "2022-02-15T17:46:11.716158",
     "exception": false,
     "start_time": "2022-02-15T17:46:11.697314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7cde29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T17:46:11.763991Z",
     "iopub.status.busy": "2022-02-15T17:46:11.763316Z",
     "iopub.status.idle": "2022-02-15T23:46:28.914120Z",
     "shell.execute_reply": "2022-02-15T23:46:28.915011Z",
     "shell.execute_reply.started": "2022-02-15T07:31:51.805691Z"
    },
    "papermill": {
     "duration": 21617.180625,
     "end_time": "2022-02-15T23:46:28.916127",
     "exception": false,
     "start_time": "2022-02-15T17:46:11.735502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Bitcoin Cash     (ID=2 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Bitcoin Cash     0.4440\n",
      "Training model for Binance Coin     (ID=0 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Binance Coin     0.2346\n",
      "Training model for Bitcoin          (ID=1 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Bitcoin          0.1250\n",
      "Training model for EOS.IO           (ID=5 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for EOS.IO           0.1728\n",
      "Training model for Ethereum Classic (ID=7 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Ethereum Classic 0.2796\n",
      "Training model for Ethereum         (ID=6 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Ethereum         0.1272\n",
      "Training model for Litecoin         (ID=9 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Litecoin         0.1375\n",
      "Training model for Monero           (ID=11)...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Monero           0.1852\n",
      "Training model for TRON             (ID=13)...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for TRON             0.1724\n",
      "Training model for Stellar          (ID=12)...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Stellar          0.2000\n",
      "Training model for Cardano          (ID=3 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Cardano          0.1343\n",
      "Training model for IOTA             (ID=8 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for IOTA             0.1731\n",
      "Training model for Maker            (ID=10)...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Maker            0.2078\n",
      "Training model for Dogecoin         (ID=4 )...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "In-sample test score for Dogecoin         0.3236\n"
     ]
    }
   ],
   "source": [
    "X_train = {}\n",
    "y_train = {}\n",
    "model_lgbm = {}\n",
    "y_insmpl_pred = {}\n",
    "score_insmpl = {}\n",
    "\n",
    "# for asset_id, asset_name in zip([10], ['Maker']):\n",
    "for asset_id, asset_name in zip(df_asset_details['Asset_ID'], df_asset_details['Asset_Name']):\n",
    "    print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})...\")\n",
    "    \n",
    "    X, y = get_asset_data(df_train, asset_id)\n",
    "    model = pipe_lgbm.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    score = get_corr(y_pred, y)\n",
    "    \n",
    "    print(f\"In-sample test score for {asset_name:<16} {score:.4f}\")\n",
    "    \n",
    "    X_train[asset_id] = X\n",
    "    y_train[asset_id] = y\n",
    "    model_lgbm[asset_id] = model\n",
    "    y_insmpl_pred[asset_id] = y_pred\n",
    "    score_insmpl[asset_id] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02974488",
   "metadata": {
    "papermill": {
     "duration": 0.029713,
     "end_time": "2022-02-15T23:46:28.975334",
     "exception": false,
     "start_time": "2022-02-15T23:46:28.945621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "ValueError: Input contains infinity or a value too large for dtype('float64').\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d70917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:29.038190Z",
     "iopub.status.busy": "2022-02-15T23:46:29.037369Z",
     "iopub.status.idle": "2022-02-15T23:46:29.046152Z",
     "shell.execute_reply": "2022-02-15T23:46:29.046678Z"
    },
    "papermill": {
     "duration": 0.043086,
     "end_time": "2022-02-15T23:46:29.046842",
     "exception": false,
     "start_time": "2022-02-15T23:46:29.003756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "df_test_all = {}\n",
    "df_pred_all = {}\n",
    "\n",
    "env = gresearch_crypto.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "004918eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:29.108050Z",
     "iopub.status.busy": "2022-02-15T23:46:29.107037Z",
     "iopub.status.idle": "2022-02-15T23:46:30.313371Z",
     "shell.execute_reply": "2022-02-15T23:46:30.313924Z"
    },
    "papermill": {
     "duration": 1.238757,
     "end_time": "2022-02-15T23:46:30.314096",
     "exception": false,
     "start_time": "2022-02-15T23:46:29.075339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for i, (df_test, df_pred) in enumerate(iter_test):\n",
    "    \n",
    "    # make predictions\n",
    "    for j, row in df_test.iterrows():\n",
    "        asset_id = row['Asset_ID']\n",
    "        try:\n",
    "            y_pred = model_lgbm[asset_id].predict(row.to_frame().T)[0]\n",
    "        except:\n",
    "            y_pred = 0.0\n",
    "            traceback.print_exc()\n",
    "        df_pred.loc[df_pred['row_id']==row['row_id'], 'Target'] = y_pred\n",
    "        \n",
    "    # store test dataframes\n",
    "    df_test_all[i] = df_test\n",
    "    df_pred_all[i] = df_pred\n",
    "    \n",
    "    # submit predictions\n",
    "    env.predict(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963e5213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:30.379849Z",
     "iopub.status.busy": "2022-02-15T23:46:30.378884Z",
     "iopub.status.idle": "2022-02-15T23:46:30.386431Z",
     "shell.execute_reply": "2022-02-15T23:46:30.386953Z"
    },
    "papermill": {
     "duration": 0.041998,
     "end_time": "2022-02-15T23:46:30.387121",
     "exception": false,
     "start_time": "2022-02-15T23:46:30.345123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_smpl_subm = 'example_sample_submission.csv'\n",
    "df_smpl_subm = pd.read_csv(os.path.join(dir_in, file_smpl_subm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4149c5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:30.453296Z",
     "iopub.status.busy": "2022-02-15T23:46:30.452350Z",
     "iopub.status.idle": "2022-02-15T23:46:30.473104Z",
     "shell.execute_reply": "2022-02-15T23:46:30.472481Z"
    },
    "papermill": {
     "duration": 0.054837,
     "end_time": "2022-02-15T23:46:30.473256",
     "exception": false,
     "start_time": "2022-02-15T23:46:30.418419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_num</th>\n",
       "      <th>row_id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_num  row_id  Target\n",
       "0          0       0       0\n",
       "1          0       1       0\n",
       "2          0       2       0\n",
       "3          0       3       0\n",
       "4          0       4       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smpl_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57079dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:30.549288Z",
     "iopub.status.busy": "2022-02-15T23:46:30.548508Z",
     "iopub.status.idle": "2022-02-15T23:46:30.551552Z",
     "shell.execute_reply": "2022-02-15T23:46:30.551001Z"
    },
    "papermill": {
     "duration": 0.046725,
     "end_time": "2022-02-15T23:46:30.551705",
     "exception": false,
     "start_time": "2022-02-15T23:46:30.504980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm_wgid = pd.DataFrame(columns = df_smpl_subm.columns)\n",
    "df_subm = pd.DataFrame(columns = ['row_id', 'Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f82e5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:30.621073Z",
     "iopub.status.busy": "2022-02-15T23:46:30.620120Z",
     "iopub.status.idle": "2022-02-15T23:46:30.637419Z",
     "shell.execute_reply": "2022-02-15T23:46:30.636784Z"
    },
    "papermill": {
     "duration": 0.053968,
     "end_time": "2022-02-15T23:46:30.637563",
     "exception": false,
     "start_time": "2022-02-15T23:46:30.583595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for group_num, df_pred in df_pred_all.items():\n",
    "    df = df_pred.copy()\n",
    "    \n",
    "    # without group_num\n",
    "    df_subm = df_subm.append(df)\n",
    "    \n",
    "    # with group_num\n",
    "    df['group_num'] = group_num\n",
    "    df_subm_wgid = df_subm_wgid.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd2746c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:30.713256Z",
     "iopub.status.busy": "2022-02-15T23:46:30.712424Z",
     "iopub.status.idle": "2022-02-15T23:46:30.715683Z",
     "shell.execute_reply": "2022-02-15T23:46:30.716154Z"
    },
    "papermill": {
     "duration": 0.046785,
     "end_time": "2022-02-15T23:46:30.716341",
     "exception": false,
     "start_time": "2022-02-15T23:46:30.669556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_num</th>\n",
       "      <th>row_id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group_num row_id    Target\n",
       "0         0      0 -0.001325\n",
       "1         0      1 -0.001756\n",
       "2         0      2 -0.001013\n",
       "3         0      3 -0.000881\n",
       "4         0      4 -0.000069"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subm_wgid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ada0699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T23:46:30.784878Z",
     "iopub.status.busy": "2022-02-15T23:46:30.784223Z",
     "iopub.status.idle": "2022-02-15T23:46:30.790996Z",
     "shell.execute_reply": "2022-02-15T23:46:30.791557Z"
    },
    "papermill": {
     "duration": 0.042924,
     "end_time": "2022-02-15T23:46:30.791731",
     "exception": false,
     "start_time": "2022-02-15T23:46:30.748807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm.to_csv('submission.csv', index=False)\n",
    "df_subm_wgid.to_csv('submission_with_group_num.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21701.946108,
   "end_time": "2022-02-15T23:46:32.326981",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-15T17:44:50.380873",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
